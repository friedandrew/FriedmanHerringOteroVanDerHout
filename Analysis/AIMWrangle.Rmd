---
title: "Wrangle"
author: "Jackie Van Der Hout"
date: "4/4/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---
---
title: "Analyses"
author: "Jackie Van Der Hout"
date: "3/27/2022"
output: pdf_document
---
Prepare for work session: working directory and packages 
```{r}
knitr::opts_chunk$set(echo = FALSE)
getwd()
#load relevant packages once analyses is determined
library(tidyverse)
library(lubridate)
library(sf)
library(corrplot)
library(dplyr)
theme_set(theme_light())
```

Importing AIM Data
```{r}
AIMraw <- st_read("https://gis.blm.gov/arcgis/rest/services/hydrography/BLM_Natl_AIM_AquADat/MapServer/0/query?where=1%3D1&text=&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&distance=&units=esriSRUnit_Foot&relationParam=&outFields=*&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&havingClause=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&historicMoment=&returnDistinctValues=false&resultOffset=&resultRecordCount=&returnExtentOnly=false&datumTransformation=&parameterValues=&rangeValues=&quantizationParameters=&featureEncoding=esriDefault&f=geojson&__ncforminfo=VmJvrSyZd1Eo2ftYuiZ2Csv3FXy8H7XoE-xtqGWFdpLoXXM_QrLBbJY-BtmB02LSjkYezZWjgMjkUQTDa0n0d7ugIiEzsdKzv1tB192rp3qdK8SWS-T_Vwxqlc6whlbENi3rrg4YqK40tpTjt0dJVWg3xwroBXxhGKT92BiR7Culk8jsk8g8cxPipo1GHHZ4oF9OZUqX8NX8gOXR3zsQRZxWmOIrkcEnN_JahqrcNjjDJXXh9ysVhdPK7UcQiEvMZy-n3fIQzqq-3YFqLGCq4ffzvu0ww4Pie6NuZD2CDkf9rilS-omAyiQq1LFJ0wVAl6PywwAseMQ4f6cDJXwLDn3BcTI3WP22jrsBYXm8SzrUZs5SGhJtMOOHN1-UMdNDFrO9rqMUXOQCTyKsmhFUFerLorYSAmMVohzr7cD03LvvdSkAQXKQpHQIcFuRqac69tN3eVlyV2IfsAA8yEcpU1GJKJx4jhwaVdXX9Sv4P1ACPp9mj3yqQ5zJqgAg0aFS6Z2O4GEd2B970yfKnbeicnbkgJTSCx0BQy3gtgkxCKujAYcWeMkvV5-dYcNF7lYQRaYvX8Eod5GUIbo8N8VNPF_USB9ZCQnlesBXLVMHXSOwH_bSq49wabgeZ2ZT7aZbJ1X8M_lXzzFieFrPzSKoOK_8_Bqcfde-Hdo8Jupndsn17KsTbpSH51tbBXOC6-3NJ0oBQuZAPkZ1I3pzzqb8sTFxIpYo2ia5lSHrZ5H-gxd753QRaQJBk1xWTyWgy8mON5hZYexZrjjUH4_C_SbY0Q%3D%3D")

#another data download option https://gbp-blm-egis.hub.arcgis.com/datasets/BLM-EGIS::blm-natl-aim-lotic-indicators-hub/about

#variable descriptions and metadata https://aim.landscapetoolbox.org/wp-content/uploads/2017/11/BLM-AIM-AquADat-Local-Feature-Class-Metadata.pdf

#more in depth metadata https://aim.landscapetoolbox.org/wp-content/uploads/2018/02/AIMLoticIndicatorMetadataUploadedDraft.pdf

#online metadata https://gis.blm.gov/arcgis/rest/services/hydrography/BLM_Natl_AIM_AquADat/MapServer/0
  
```

Exploratory Data Analysis 
```{r}
#repeat for both datasets
unique(AIMraw$PRJCT)

WAAIM <- AIMraw %>% 
  filter(PRJCT == "WA_SpokaneDO") 

SiteVisits <- WAAIM %>% 
  group_by(SITE_CD) %>% 
  summarise(columnname = n()) 
#all sites were only sampled once 

rm(AIMraw)

class()
colnames()
summary()
```

Data Tidying 
```{r}
#AIM Data

WAAIM_tidy <- WAAIM %>% 
  select(OBJECTID, SITE_CD, "StreamName" = STRM_NM, MIDLAT, MIDLONG, "StreamOrder" = STRM_ORDR, BTMLAT, BTMLONG, TRLAT, TRLONG, "ReachLength" = TOT_RCH_LEN, "PercentCover" = PCT_OVRHD_CVR, VEG_CMPLXTY, RPRN_VEG_CNPY_CVR, RPRN_VEG_UNDRSTRY_CVR, RPRN_VEG_GC, NON_NTVE_WDY, NTVE_WDY, NON_NTVE_HRB, NTVE_HRB, SDGE_RSH, OBSRVD_INVRT_RCHNSS, EXPCTD_INVRT_RCHNSS, MACROINVRTBRTE_CNT, "TotalN" = TTL_N, "PredictedN" = PRD_TTL_N, "TotalP" = TTL_P, "PredictedP" = PRD_TTL_P, "SpC" = SPCFC_CNDCTNCE, "PredictedSpC" = PRD_SPCFC_CNDCTNCE, pH, INSTNT_TEMP, "PercentPools" = PCT_PL, "AvgPoolDepth" = RES_PL_DEP, "NumberPools" = NM_PL, LWD_FREQ, "LWDVolume" = LWD_VL, "PercentFines2" = PCT_FN2, "PercentFines6" = PCT_FN6, D16, D84, D50, BNK_STBLTY, BNK_CVR_LWD, BNKFLL_HT, INCSN_HT, CHN_INCSN, THLWG_DEP_MN, PCT_DRY, BNKFLL_WT, WTTD_WT, "FloodWidth" = FLD_WT, "EntrenchmentRatio" = ENTRCH, SLPE, SNSTY, BVR_SGN, geometry)

rm(WAAIM)

#think about which lat-long columns it makes sense to use 

#run a correlation analyses within the dataset 
#remove highly correlated variables 

#set as sf object

#Dam Data
#set as sf object

#Background Map Data 
#set as sf object
```

Exploring the tidied data 
```{r}
#ggplot(USGS.flow.data, aes(x = discharge.mean)) +
  #geom_histogram(binwidth = 10) + 
  #scale_x_continuous(limits = c(0, 500))

#exploratory analysis of the means across states, regions, HUCs
#statistical tests, timeseries, etc 
#go through problem sets and see what might be applicable 
```

After data exploration: state research question, hypothesis and null hypothesis 
  -spatial - distance from some pollution source or dams changing water quality? 
  -any pattern across variables, time, spatial groupings, or mixture thereof 

Data Wrangling (see 03_DataExploration_Part2.rmd for more graph examples)
```{r}
#select for locations in WA 
#NTL.phys.data.PeterPaul <- filter(NTL.phys.data, lakename %in% c("Paul Lake", "Peter Lake")) 

#once wrangled, save data as csv
#write.csv(NTL.phys.data.PeterPaul1, row.names = FALSE, file = "../../Environmental_Data_Analytics_2022/Data/Processed/AIMProcessed.csv")
```

Calculating River Distance Options
```{r}
#river dist package https://github.com/mbtyers/riverdist

#alternate river distance calculation method https://fsdias.github.io/flow_distance.md/
#river mile calculator outside of R https://waterdata.usgs.gov/wa/nwis/current?type=rivermi

#bin sites into upstream or downstream of dam
#add column with mutate function correlating above or below dam
#another column for distance 
#to calculate that distance, it needs to be calculated along the stream 
#to calculate that use the riverdist package https://github.com/mbtyers/riverdist
#within that there is the river distance function
#I will need to grab the shapefiles (background map) 
#NHD+ tools will have the background map with the streams https://usgs-r.github.io/nhdplusTools/
#bin directly downstream and distance downstream 
#make sure that all of the files are in the same projection before doing the analysis #projection of the basemap is what the other two files should be in 
```

ndhplus & intersectr attempt
https://github.com/USGS-R/intersectr
```{r}
# library(nhdplusTools)
# site <- list(featureSource = #"nwissite",
#                featureID = #"USGS-10128500")
# line <- navigate_nldi(site, "UT", "")
# site <- navigate_nldi(site, "UT", #"nwissite")
# 
# nhdp <- subset_nhdplus(#ut$nhdplus_comid,
#                        #"nhdp_subset.gpkg",
#                       #"download")
#   
# nhdplusTools::get_flowline_index(
#   points = sites, 
#   flines = flowline,
#   searchradius = 100, #units of flowlines
#   precision = 10), #max node spacing
# 
# #spatial intersection
# #could be used to intersect dam and sample locations to flow lines? 
# #install.packages("devtools")
# library(devtools)
# #be forewarned -- HUGE DOWNLOAD!!!!
# #devtools::install_github("USGS-R/intersectr")
# library(intersectr)
# cells <- create_cell_geometry(x_coords, y_coords, nc_projections, catchment)
# poly <- sf::st_as_sf(dplyr::select(catchment, ID = featureid))
# weights <- calculate_area_intersection_weights(cells, poly)
# dap_uri <- "#metadatalink"
# execute_intersection(nc_file = dap_uri,
#                      variable name = #"precipitation_amount", 
#                 intersection_weights = weights,
#                 cell_geometry = data_source_cells,
#                 x_var = x_coord, y_var = y_coord, t_var = t_coord, 
#                 start_datetime = #"",
#                 end_datetime = #"")
                  
```


Visualize Data - check https://www.data-to-viz.com/ for more ideas 
```{r}

#ggplot(subset(PeterPaul.chem.nutrients, depth == 0),aes(x = daynum, y = temperature_C, color = as.factor(year4)))+
  #geom_point()+
  #facet_wrap(vars(lakename), nrow = 2)+
  #labs(y = "Temperature C") 

#nutrient plot, can be adjusted & done with facet_wrap
#Nutrientplot6 <-
 #ggplot(PeterPaul.chem.nutrients) +
  #geom_freqpoly(aes(x = tn_ug), color = "darkred") +
 #geom_freqpoly(aes(x = tp_ug), color = "darkblue") +
  #geom_freqpoly(aes(x = nh34), color = "blue") +
  #geom_freqpoly(aes(x = no23), color = "royalblue") +
  #geom_freqpoly(aes(x = po4), color = "red") 
#print(Nutrientplot6)
```

Space for any statistical analyses (t-test, ANOVAs, GLMs, linear regressions etc)
For example, comparing the means of a series of analytes that are and are not within X range proximity of an upstream dam.
See 06_Lab_GLMs.Rmd for outline and guides to selecting appropriate statistical tests. 

```{r correlation-check}

# Specify columns want to change to numeric
#Change integer columns to numeric b/c corr can only be run on numeric columns

i <- c(1, 6, 17:22, 24, 35, 40:44)  

#convert the columns indicated in i above to numeric
WAAIM_tidy[ , i] <- apply(WAAIM_tidy[ , i], 2,            # Specify own function within apply
                    function(x) as.numeric(as.character(x)))

#check that the all integers except for object ID are now numeric
sapply(WAAIM_tidy, class)

#drop nas so can run a corr
WAAIM_tidy <- drop_na(WAAIM_tidy)

#select for numeric columns to run the corr on
WAAIM_tidy_numeric <- WAAIM_tidy %>%
  select(c(1,4:47))

#drop the geometry column cor b/c cor only runs on numeric columns
WAAIM_tidy_numeric <- st_set_geometry(WAAIM_tidy_numeric, NULL)

#check if geometry column removed
head(WAAIM_tidy_numeric)

# create a correlation matrix. Necessitates only complete cases. Needs to be its own data matrix. Use corr to create the matrix so all variables are the columns and rows and their correlation btw each other is calculated. The dark blue diagonal down the middle is b/c when something correlated against itself is 1. Used to see how covariates are related aka correlated
WAAIMcorr <- cor(WAAIM_tidy_numeric)

# plot correlation matrix.
corrplot(WAAIMcorr)

# customize so that only the upper half shows since the upper and lower (compared to the diagonal mirrors itself) with the type, diag = FALSE gets the self-correlation removed, endings change the text 
corrplot(WAAIMcorr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#That plot is heinous. Too many variables. Checking correlation between varibales that are categorized together in the AIM metadata.

#selecting water quality columns and run correlation
water_quality <- WAAIM_tidy_numeric %>% 
  select(c(23:30))

water_corr <- cor(water_quality)
corrplot(water_corr)
corrplot(water_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#selecting Biodiversity and Riparian Habitat Quality columns and run correlation
#left out non-native woody veg b/c 0 for all sites
riparian_quality <- WAAIM_tidy_numeric %>% 
  select(c(11:14, 16:22))

rip_corr <- cor(riparian_quality)
corrplot(rip_corr)
corrplot(rip_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#selecting Watershed Function and Instream Habitat Quality and run correlation
instream_quality <- WAAIM_tidy_numeric %>% 
  select(c(31:45))

inst_corr <- cor(instream_quality)
corrplot(inst_corr)
corrplot(inst_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")
```

#correlation with upstream dams
```{r dam correlation}
#read in updated data with number of upstream dams attached. Warning is okay.
WAAIM_tidy_dams <- st_read("./New Data/WAAIM_tidy_dams.csv")

head(WAAIM_tidy_dams)

#select out the numberof dams upstream column
upstream_dams <- WAAIM_tidy_dams %>% 
  select(OBJECTID, Number_of_dams_upstream)

view(upstream_dams)

#change both columns to numeric

numb <- c(1,2)  

upstream_dams[ , numb] <- apply(upstream_dams[ , numb], 2,            # Specify own function within apply
                    function(x) as.numeric(as.character(x)))

sapply(upstream_dams, class)

#merge the dfs, must be the same class to merge
WAAIM_tidy_dams_merge = WAAIM_tidy_numeric %>% left_join(upstream_dams,by="OBJECTID")
WAAIM_tidy_dams_merge

head(WAAIM_tidy_dams_merge)

# create a correlation matrix. Necessitates only complete cases. Needs to be its own data matrix. Use corr to create the matrix so all variables are the columns and rows and their correlation btw each other is calculated. The dark blue diagonal down the middle is b/c when something correlated against itself is 1. Used to see how covariates are related aka correlated
WAAIMcorr <- cor(WAAIM_tidy_dams_merge)

# plot correlation matrix.
corrplot(WAAIMcorr)

# customize so that only the upper half shows since the upper and lower (compared to the diagonal mirrors itself) with the type, diag = FALSE gets the self-correlation removed, endings change the text 
corrplot(WAAIMcorr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#That plot is heinous. Too many variables. Checking correlation between variables that are categorized together in the AIM metadata.

#selecting water quality columns and number of dams and run correlation
water_quality <- WAAIM_tidy_dams_merge %>% 
  select(c(23:30, 46))

water_corr <- cor(water_quality)
corrplot(water_corr)
corrplot(water_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#selecting Biodiversity and Riparian Habitat Quality columns and number of dams and run correlation
#left out non-native woody veg b/c 0 for all sites
riparian_quality <- WAAIM_tidy_dams_merge %>% 
  select(c(11:14, 16:22, 46))

rip_corr <- cor(riparian_quality)
corrplot(rip_corr)
corrplot(rip_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

#selecting Watershed Function and Instream Habitat Quality and number of dams and run correlation
instream_quality <- WAAIM_tidy_dams_merge %>% 
  select(c(31:46))

inst_corr <- cor(instream_quality)
corrplot(inst_corr)
corrplot(inst_corr, type = "upper", diag = FALSE, tl.cex = 0.8, tl.col = "black")

```




## Results of the correlation check -> update once add the number of dams in

Water Quality

Biodiversity and Riparian Habitat Quality

Watershed Function and Instream Habitat Quality


```{r AIC}
#select the variables from the correlation plots, save this for further analyses 

# AIM_AIC <- lm(data = AIM_AIC_data, tp_ug ~ depth + dissolvedOxygen + 
#               temperature_C + tn_ug + po4)
# 
# #Choose a model by AIC in a Stepwise Algorithm
# step(AIM_AIC)
# AIMmodel <- lm(data = Paul.naomit, tp_ug ~ dissolvedOxygen + temperature_C + tn_ug)
# summary(AIMmodel)
# ```


```{r}
##example only 
#checking for normality
shapiro.test(EPAair$Ozone[EPAair$Year == 2018])
shapiro.test(EPAair$Ozone[EPAair$Year == 2019])

#p-value less than 0.05 then reject null for 2018 and 2019 i.e. data do not follow normal distribution

#Compare variance using F-test (only)
var.test(EPAair$Ozone ~ EPAair$Year)

#p-value less than 0.05 then reject null for 2018 and 2019 i.e. true ratio not equal to one

ggplot(EPAair, aes(x = Ozone, color = as.factor(Year))) +
  geom_freqpoly()

# Format as a t-test
O3.twosample <- t.test(EPAair$Ozone ~ EPAair$Year)
O3.twosample
O3.twosample$p.value
#reject null hypothesis
#the means are not the same for 2018/2019 
#or there is not enough data for means to be the same 

# Format as a GLM
O3.twosample2 <- lm(EPAair$Ozone ~ EPAair$Year)
summary(O3.twosample2)
#GLM gives the same p-value

plot(O3.twosample2)

```

*Time series is probably not relevant to this project due to the nature of the data.* 

Spatial analyses
```{r}

```

**Notes for End of Project**
*Make sure that the README.md file is updated 
*If working on a specific basin, add image of basin in final report
*Check through grading checklist
*Go through project Rmd files provided by professors
*Go through crafting reports lessons for formatting tips 
*Consider making an RShiny dashboard if extra time / energy 